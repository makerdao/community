---
title: "The Intracacies of Search"
authors: ["andytudhope", "MaximumCrash", "twblack88", "annaalexakr"]
date: 2021-04-02
image: "3"
---

_The MakerDAO Community Blog has no affiliation with the Maker Foundation. It is independently created and curated by Community members. None of the content displayed hereon either represents or is endorsed or approved by the Maker Foundation, its executives, board of directors, employees or contractors._

We began implementing search using [Algolia](https://www.algolia.com/), but then pivoted to [Lunr](https://lunrjs.com/). The pros were obvious:
no server side apis, no external requests, search indexing as a part of the build process.
It was everything we got out of the old Algolia integration but without the need to manage yet
another service. The integration works well, yet it took some time to understand how the indexing
is handled.

## Why Lunr

Algolia is great, but it has limits since it's SaaS (software as service). The indexing and tools
they provide are fantastic, and if this were a project that had a larger dependency on search we'd
consider it. However, that's not the case. We don't need an extremely robust elastic search engine
to index our content pages. We just need a search that meets the minimal requirements of being search.

Lunr is also used widely. If you've used mkdocs or docusaurus recently then you've used Lunr.

## How Lunr Indexes

Since we're using Gatsby, there's almost always an integration someone has built, and luckily we have
the [gatsby-plugin-lunr](https://www.gatsbyjs.com/plugins/gatsby-plugin-lunr/) that does a lot of heavy lifting for us. We provide languages and how to filternodes
in the options of our plugin in the `gatsby-config` like so:

```js:title=gatsby-config.js
options: {
  languages: [
    {
      name: "en",
      filterNodes: (node) =>
        node.frontmatter !== undefined &&
        node.fileAbsolutePath &&
        node.fileAbsolutePath.match(
          /\/en\/(?!header.mdx|index.mdx|404.mdx|.js|.json)/
        ) !== null,
    },
  ];
}
```

<CTA>


Here, we filter out nodes that don't have frontmatter, don't have an absolute path, and the
path doesn't match any file at the top section of our locale like header.mdx, index.mdx, 404.mdx, ect.)

</CTA>


For every new locale we add, we just make sure to update it's name, and the regex match `/\/[LOCALE]\/(?!header.mdx|index.mdx|404.mdx|.js|.json)/`.

We also provide it with which fields to index, if they should store it, and how it should be weighted:

```js:title=gatsby-config.js
fields: [
          { name: "title", store: true, attributes: { boost: 20 } },
          { name: "keywords", attributes: { boost: 15 } },
          { name: "url", store: true },
          { name: "excerpt", store: true, attributes: { boost: 5 } },
        ],
```

Then comes the hard part. How the fields get populated.
We provide Lunr with resolvers that match the key we would provide when querying through GraphQL.
However, Lunr prefaces its resolvers with `all`, so `Mdx` refers too `allMdx` in GraphQL:

```js:title=gatsby-config.js
resolvers: {
          Mdx: {
              title: TitleConverter,
              url: UrlConverter,
                ...
```

Since we also have some rules around what a Title is and how the URL is provided from the data we have
(remember, automagic) we added some util methods that take in a node and transforms its data to meet our needs (TitleConverter, UrlConverter, etc).

Providing an excerpt on search requires more work, since the excerpt is supposed to be our compiled MDX in HTML form.
However, that doesn't happen during build time, so `excerpt` is undefined due to a timing issue with Lunr.
The solution is to

1. Use the description from the frontmatter if provided, or
2. use the `rawBody` and parse it manually like so:

```js:title=gatsby-config.js
excerpt: (node) => {.
              if (node.frontmatter.description) {
                return node.frontmatter.description;
              }
              const excerptLength = 136; // Hard coded excerpt length
              let excerpt = "";
              const tree = remark()
                .use(remarkFrontmatter)
                .use(removeFrontmatter)
                .parse(node.rawBody);
              visit(tree, "text", (node) => {
                excerpt += node.value;
              });
              return `${excerpt.slice(0, excerptLength)}${
                excerpt.length > excerptLength ? "..." : ""
              }`;
            },
```

<List>


<Link to="/en/blog/community/Engineering-for-communities">


Engineering For Communities: Part 1

</Link>


<Link to="/en/blog/community/eng-search">


**The Intracacies of Search: Part 2**

</Link>


<Link to="/en/blog/community/eng-navigation">


Navigating Through Automagic: Part 3

</Link>


<Link to="/en/blog/community/eng-language">


Translations for Global Communities: Part 4

</Link>


</List>

